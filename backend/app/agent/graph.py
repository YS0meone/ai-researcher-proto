from langchain_core.tools import tool
from app.db.schema import S2Paper
from app.agent.paper_finder import paper_finder
from app.agent.paper_finder_fast import paper_finder_fast_graph
from app.agent.qa import qa_graph
from typing import Tuple
from langgraph.graph import StateGraph
from app.agent.states import State
import logging
from app.core.config import settings
from langchain.chat_models import init_chat_model
from langgraph.graph import START, END
from app.agent.utils import setup_langsmith
from pydantic import BaseModel, Field
from langchain.messages import SystemMessage, AIMessage, ToolMessage, HumanMessage
from app.tools.search import get_paper_details
from langgraph.types import Command
from langchain.tools import ToolRuntime
from langchain.agents import create_agent

setup_langsmith()
logger = logging.getLogger(__name__)

@tool
def find_papers(runtime: ToolRuntime) -> Command:
    """
    Find papers using the optimized query generated by the previous workflow.
    It would update the current papers list with the new papers found.
    Trust the result from the tools would find the most relevant papers.
    """

    user_query = runtime.state.get("optimized_query", "")
    papers = runtime.state.get("papers", [])

    state = {"optimized_query": user_query, "papers": papers, "messages": [HumanMessage(content=user_query)]}
    result = paper_finder_fast_graph.invoke(state)
    return Command(
        update={"papers": result["papers"], 
        "messages": [ToolMessage(content=f"I found {len(result['papers'])} papers for your query.", tool_call_id=runtime.tool_call_id)]
        })

@tool
def answer_question(runtime: ToolRuntime) -> str:
    """
    Answer the user question based on the current papers.
    Trust the result from the tools would answer the user question based on the papers and forward the answer to the user.
    """
    # user_query = runtime.state.get("optimized_query", "")
    # papers = runtime.state.get("papers", [])
    # state = {"messages": [{"role": "user", "content": user_query}], "papers": papers}
    # result = qa_graph.invoke(state)
    # return result["messages"][-1].content
    return "I'm sorry, I can't answer that question."

def query_clarification(state: State):
    system_prompt = f"""
    You are an expert in clarifying user queries for a research assistant.
    You need to decide if the user's query is clear or it needs clarification.
    Take the previous messages into account if there is any.
    Make the decision and provide your reasoning for the decision.
    """
    
    class QueryIsClear(BaseModel):
        reasoning: str = Field(description="The reasoning why the user's query is clear")

    class QueryNeedsClarification(BaseModel):
        reasoning: str = Field(description="The reasoning why the user's query needs clarification")
        clarification: str = Field(description="The clarification for the user's query")
    
    tools = [QueryIsClear, QueryNeedsClarification]
    structured_model = supervisor_model.bind_tools(tools, tool_choice="any")
    msg = structured_model.invoke([
        SystemMessage(content=system_prompt)
    ] + state["messages"])
    
    response = msg.tool_calls[0]["args"]

    if "clarification" not in response:
        return {"messages": [AIMessage(content="The user's query is clear.")], "is_clear": True}
    else:
        return {"messages": [AIMessage(content=response["clarification"])], "is_clear": False}

def query_optimization(state: State):
    system_prompt = f"""
    You are an expert in optimizing user queries for a search agent for academic papers.
    Your goals is to rephrase the user query to be more specific and to be more likely to help the subagent find the most relevant papers and answer the user's question.
    There might be some clarification happened before this node, you should take that into account.
    If the user's query is good enough, you may repeat the user's query as the optimized query or change it slightly to be more specific.
    If the user's query is not good enough, you should optimize it.
    The optimized query should be self-contained and should not require any additional context.
    """

    class QueryOptimizationOutput(BaseModel):
        reasoning: str = Field(description="The reasoning for your optimization")
        optimized_query: str = Field(description="The optimized query for the user's query")

    tools = [QueryOptimizationOutput]
    structured_model = supervisor_model.bind_tools(tools, tool_choice="QueryOptimizationOutput")
    msg = structured_model.invoke([
        SystemMessage(content=system_prompt)
    ] + state["messages"])
    response = msg.tool_calls[0]["args"]

    message = f"The optimized query is: {response['optimized_query']}\n\nReasoning: {response['reasoning']}"
    
    return {"messages": [AIMessage(content=message)], "optimized_query": response['optimized_query']}

def should_clarify(state: State):
    is_clear = state.get("is_clear", True)
    route = "optimize" if is_clear else "end"
    return route

supervisor_model = init_chat_model(model=settings.AGENT_MODEL_NAME, api_key=settings.GEMINI_API_KEY, parallel_tool_calls=False)
tools = [find_papers, answer_question, get_paper_details]

supervisor_prompt = """
You are a supervisor for a research assistant system.
You are provided with three tools: find_papers, answer_question and get_paper_details.
The find_papers tool is used to find papers related to the user query.
The answer_question tool is used to answer the user question based on the papers.
The get_paper_details tool is used to get the details of a paper currently in the paper list.

You need to decide which tool to use based on the user query and the current papers you have.
You need to use the find_papers tool if the current papers you have is not enough to answer the user question.
You need to call the answer_question tool if the current papers you have is enough to answer the user question.
You should only call one tool at a time.
You should blindly trust the find_papers tool would find the most relevant papers and the answer_question tool would answer the user question based on the papers.
Sometimes you only need to call one tool. 
For example, if the user's query is purely about finding papers that interest them, you can just call the find_paper tool
If the user's query can be answered directly using the current paper list, you can just call the answer question tool
After you call the answer_question tool, you should forward the tool call result to the user and end the conversation.
"""

supervisor_node = create_agent(supervisor_model, tools, state_schema=State, system_prompt=supervisor_prompt)


graph = StateGraph(State)
graph.add_node("query_clarification", query_clarification)
graph.add_node("query_optimization", query_optimization)
graph.add_node("supervisor", supervisor_node)

graph.add_edge(START, "query_clarification")
graph.add_conditional_edges("query_clarification", should_clarify, {"optimize": "query_optimization", "end": END})
graph.add_edge("query_optimization", "supervisor")
graph.add_edge("supervisor", END)

graph = graph.compile()