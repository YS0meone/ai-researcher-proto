"""
ç®€åŒ–çš„æ•°æ®åŠ è½½è„šæœ¬ - å•è¿›ç¨‹ç‰ˆæœ¬ï¼ˆé€‚ç”¨äºWindowsï¼‰
"""
import json
from tqdm import tqdm
from app.core.config import settings
from app.services.elasticsearch import ElasticsearchService
from app.db.schema import ArxivPaper

def main():
    print("="*60)
    print("ğŸ”¬ Simple Paper Loader (Single Process)")
    print("="*60)
    
    # åˆå§‹åŒ–ElasticsearchæœåŠ¡
    es_service = ElasticsearchService(settings.elasticsearch_config)
    
    # CSç±»åˆ«
    cs_categories = [
        'cs.AI', 'cs.AR', 'cs.CC', 'cs.CE', 'cs.CG', 'cs.CL', 'cs.CR', 'cs.CV',
        'cs.CY', 'cs.DB', 'cs.DC', 'cs.DL', 'cs.DM', 'cs.DS', 'cs.ET', 'cs.FL',
        'cs.GL', 'cs.GR', 'cs.GT', 'cs.HC', 'cs.IR', 'cs.IT', 'cs.LG', 'cs.LO',
        'cs.MA', 'cs.MM', 'cs.MS', 'cs.NA', 'cs.NE', 'cs.NI', 'cs.OH', 'cs.OS',
        'cs.PF', 'cs.PL', 'cs.RO', 'cs.SC', 'cs.SD', 'cs.SE', 'cs.SI', 'cs.SY'
    ]
    cs_set = set(cs_categories)
    
    # æ‰“å¼€æ–‡ä»¶
    data_path = settings.paper_loader_config.arxiv_metadata_path
    print(f"\nğŸ“ Reading from: {data_path}")
    print(f"ğŸ·ï¸  Looking for CS categories: {len(cs_categories)} types\n")
    
    processed = 0
    added = 0
    limit = 50000  # åŠ è½½50000ç¯‡è®ºæ–‡ï¼Œé¢„è®¡èƒ½å¾—åˆ°~2000ç¯‡CSè®ºæ–‡
    
    with open(data_path, 'r', encoding='utf-8') as f:
        for line in tqdm(f, total=limit, desc="Processing papers"):
            if processed >= limit:
                break
            
            try:
                data = json.loads(line)
                processed += 1
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯CSç±»åˆ«
                categories = data.get('categories', '')
                if not categories:
                    continue
                
                cat_list = categories.split()
                if not any(cat in cs_set for cat in cat_list):
                    continue
                
                # åˆ›å»ºArxivPaperå¯¹è±¡
                paper = ArxivPaper(
                    id=data['id'],
                    title=data.get('title', ''),
                    abstract=data.get('abstract', ''),
                    authors=data.get('authors'),
                    submitter=data.get('submitter'),
                    comments=data.get('comments'),
                    journal_ref=data.get('journal-ref'),
                    doi=data.get('doi'),
                    report_no=data.get('report-no'),
                    categories=categories,
                    license=data.get('license')
                )
                
                # æ·»åŠ åˆ°Elasticsearch
                if es_service.add_paper(paper):
                    added += 1
                
            except Exception as e:
                print(f"\nâŒ Error processing line: {e}")
                continue
    
    print(f"\n{'='*60}")
    print(f"ğŸ“ˆ Final Statistics")
    print(f"{'='*60}")
    print(f"âœ… Processed: {processed:,} lines")
    print(f"âœ… Added: {added:,} CS papers")
    print(f"ğŸ“Š Match rate: {(added/processed*100):.1f}%")
    print(f"{'='*60}")

if __name__ == "__main__":
    main()
